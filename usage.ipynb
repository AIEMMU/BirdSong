{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "numerous-saudi",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchaudio\\extension\\extension.py:14: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchaudio\\backend\\utils.py:64: UserWarning: The interface of \"soundfile\" backend is planned to change in 0.8.0 to match that of \"sox_io\" backend and the current interface will be removed in 0.9.0. To use the new interface, do `torchaudio.USE_SOUNDFILE_LEGACY_INTERFACE = False` before setting the backend to \"soundfile\". Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  'The interface of \"soundfile\" backend is planned to change in 0.8.0 to '\n"
     ]
    }
   ],
   "source": [
    "#Load in the libraries we need \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from glob import glob\n",
    "import librosa\n",
    "from model import get_model, create_model # this creates our model\n",
    "\n",
    "from dataloader import get_dataloader # this is the data file\n",
    "from metrics import LWLRAP, label_ranking_average_precision_score # metrics\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-highland",
   "metadata": {},
   "source": [
    "### Load in the dataset to evaluate or test on\n",
    "\n",
    "Here we are using Christian's test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "flying-shade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>File</th>\n",
       "      <th>Event_ID</th>\n",
       "      <th>X_min</th>\n",
       "      <th>X_max</th>\n",
       "      <th>Y_min</th>\n",
       "      <th>Y_max</th>\n",
       "      <th>Species</th>\n",
       "      <th>EngName</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date</th>\n",
       "      <th>recID</th>\n",
       "      <th>wave</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AshDro</td>\n",
       "      <td>extr_1670_B09_20190727_060000_All_Day_3h.txt</td>\n",
       "      <td>AshDro_1</td>\n",
       "      <td>3657.588</td>\n",
       "      <td>9824.903</td>\n",
       "      <td>1.788462</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>Dicrurus leucophaeus</td>\n",
       "      <td>Ashy Drongo</td>\n",
       "      <td>Birds</td>\n",
       "      <td>27/07/2019</td>\n",
       "      <td>B09</td>\n",
       "      <td>extr_1670_B09_20190727_060000_All_Day_3h.wav</td>\n",
       "      <td>6167.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AshDro</td>\n",
       "      <td>extr_1670_B09_20190727_060000_All_Day_3h.txt</td>\n",
       "      <td>AshDro_2</td>\n",
       "      <td>10622.568</td>\n",
       "      <td>12178.988</td>\n",
       "      <td>2.153846</td>\n",
       "      <td>4.153846</td>\n",
       "      <td>Dicrurus leucophaeus</td>\n",
       "      <td>Ashy Drongo</td>\n",
       "      <td>Birds</td>\n",
       "      <td>27/07/2019</td>\n",
       "      <td>B09</td>\n",
       "      <td>extr_1670_B09_20190727_060000_All_Day_3h.wav</td>\n",
       "      <td>1556.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AshDro</td>\n",
       "      <td>extr_1676_B01_20190718_060000_All_Day_3h.txt</td>\n",
       "      <td>AshDro_3</td>\n",
       "      <td>291.829</td>\n",
       "      <td>2295.720</td>\n",
       "      <td>1.361702</td>\n",
       "      <td>3.593381</td>\n",
       "      <td>Dicrurus leucophaeus</td>\n",
       "      <td>Ashy Drongo</td>\n",
       "      <td>Birds</td>\n",
       "      <td>18/07/2019</td>\n",
       "      <td>B01</td>\n",
       "      <td>extr_1676_B01_20190718_060000_All_Day_3h.wav</td>\n",
       "      <td>2003.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AshDro2</td>\n",
       "      <td>extr_1463_B05_20181212_000009_All_Day.txt</td>\n",
       "      <td>AshDro2_1</td>\n",
       "      <td>5243.020</td>\n",
       "      <td>8965.874</td>\n",
       "      <td>1.732360</td>\n",
       "      <td>2.355231</td>\n",
       "      <td>Dicrurus leucophaeus</td>\n",
       "      <td>Ashy Drongo</td>\n",
       "      <td>Birds</td>\n",
       "      <td>12/12/2018</td>\n",
       "      <td>B05</td>\n",
       "      <td>extr_1463_B05_20181212_000009_All_Day.wav</td>\n",
       "      <td>3722.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AshDro3</td>\n",
       "      <td>extr_1673_B05_20190729_060000_All_Day_3h.txt</td>\n",
       "      <td>AshDro3_1</td>\n",
       "      <td>5700.389</td>\n",
       "      <td>7821.012</td>\n",
       "      <td>1.734940</td>\n",
       "      <td>5.686747</td>\n",
       "      <td>Dicrurus leucophaeus</td>\n",
       "      <td>Ashy Drongo</td>\n",
       "      <td>Birds</td>\n",
       "      <td>29/07/2019</td>\n",
       "      <td>B05</td>\n",
       "      <td>extr_1673_B05_20190729_060000_All_Day_3h.wav</td>\n",
       "      <td>2120.623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                          File   Event_ID  \\\n",
       "0   AshDro  extr_1670_B09_20190727_060000_All_Day_3h.txt   AshDro_1   \n",
       "1   AshDro  extr_1670_B09_20190727_060000_All_Day_3h.txt   AshDro_2   \n",
       "2   AshDro  extr_1676_B01_20190718_060000_All_Day_3h.txt   AshDro_3   \n",
       "3  AshDro2     extr_1463_B05_20181212_000009_All_Day.txt  AshDro2_1   \n",
       "4  AshDro3  extr_1673_B05_20190729_060000_All_Day_3h.txt  AshDro3_1   \n",
       "\n",
       "       X_min      X_max     Y_min     Y_max               Species  \\\n",
       "0   3657.588   9824.903  1.788462  4.250000  Dicrurus leucophaeus   \n",
       "1  10622.568  12178.988  2.153846  4.153846  Dicrurus leucophaeus   \n",
       "2    291.829   2295.720  1.361702  3.593381  Dicrurus leucophaeus   \n",
       "3   5243.020   8965.874  1.732360  2.355231  Dicrurus leucophaeus   \n",
       "4   5700.389   7821.012  1.734940  5.686747  Dicrurus leucophaeus   \n",
       "\n",
       "       EngName  Group        Date recID  \\\n",
       "0  Ashy Drongo  Birds  27/07/2019   B09   \n",
       "1  Ashy Drongo  Birds  27/07/2019   B09   \n",
       "2  Ashy Drongo  Birds  18/07/2019   B01   \n",
       "3  Ashy Drongo  Birds  12/12/2018   B05   \n",
       "4  Ashy Drongo  Birds  29/07/2019   B05   \n",
       "\n",
       "                                           wave  duration  \n",
       "0  extr_1670_B09_20190727_060000_All_Day_3h.wav  6167.315  \n",
       "1  extr_1670_B09_20190727_060000_All_Day_3h.wav  1556.420  \n",
       "2  extr_1676_B01_20190718_060000_All_Day_3h.wav  2003.891  \n",
       "3     extr_1463_B05_20181212_000009_All_Day.wav  3722.854  \n",
       "4  extr_1673_B05_20190729_060000_All_Day_3h.wav  2120.623  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../labels_test_CD_20210309.csv');df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-folks",
   "metadata": {},
   "source": [
    "## Load the classes\n",
    "We need to load the classes that the models were trained on, in this case, that is the 51 class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ranking-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.loadtxt('class_birds_51.txt', dtype='str', delimiter='\\n')\n",
    "classes = list(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-minute",
   "metadata": {},
   "source": [
    "We first preprocess the data, so that it can be used by our dataloaders. \n",
    "\n",
    "This includes adding a recording_id so that it may load the correct audio file, and a species_id if you are evaluating some data. There is also the oppertunity to drop classes that are not in the classes file to test how well it performs on just these classes.  \n",
    "\n",
    "This function below ouputs a a preprocessed CSV file, a prediction and labels file as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "posted-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, classes=[], drop_classes= False, mode='test'):\n",
    "           \n",
    "    df['recording_id'] = [f[:-4] for f in df.File]\n",
    "    #appends a species id\n",
    "    #if the species is not within the classes it is labeled as an unknown#\n",
    "    if mode !='test':\n",
    "        df['species_id'] = [-1 if s not in classes else classes.index(s) for s in df.Species] \n",
    "        if drop_classes == True:\n",
    "            df = df[df.Species.isin(classes)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    #preprare a output file of the predictions from the model\n",
    "    species_cols = [f'{classes[i]}' for i in range(len(classes))]\n",
    "    cv_preds = pd.DataFrame(columns=species_cols)\n",
    "    cv_preds['recording_id'] = df['recording_id'].drop_duplicates()\n",
    "    cv_preds.loc[:, species_cols] = 0\n",
    "    cv_preds = cv_preds.reset_index(drop=True)\n",
    "    \n",
    "    if mode == 'test':\n",
    "        return df, cv_preds, species_cols\n",
    "    return df, cv_preds,species_cols, cv_preds.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-heather",
   "metadata": {},
   "source": [
    "## Evaluation loop\n",
    "\n",
    "This is the evaluation loop, that loads the model, creates a dataloader and passes the data to the model. It then processes the predictions from the model, and addits it to a prediction csv, and the appropriate label to the labels csv file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "native-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_loop(paths,species_cols, df, config, cv_preds, labels_df, model, device):\n",
    "\n",
    "    for path in paths:\n",
    "        print(f'loading model {path}')\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model.eval()\n",
    "        #load the data into dataloaders\n",
    "        dataloader = get_dataloader(df, config=config, mode='val')\n",
    "\n",
    "        tk = tqdm(dataloader, total=len(dataloader))\n",
    "        sub_index = 0\n",
    "        with torch.no_grad():\n",
    "            #we go through all of the data\n",
    "            for i, (im,l) in enumerate(tk):\n",
    "                #pass it to the cpu or gpu\n",
    "                im = im.to(device)\n",
    "                #predict on the data\n",
    "                for i, x_partial in enumerate(torch.split(im, 1, dim=1)):\n",
    "                    x_partial = x_partial.squeeze(1)\n",
    "                    if i == 0:\n",
    "                        preds = model(x_partial)\n",
    "                    else:\n",
    "                        # take max over predictions\n",
    "                        preds = torch.max(preds, model(x_partial))\n",
    "                    #get the confidence score of each species and add it to the csv file\n",
    "                o = preds.sigmoid().cpu().numpy()\n",
    "                for val, ll in zip(o,l.cpu().numpy()):\n",
    "                    cv_preds.loc[sub_index, species_cols] += val\n",
    "                    labels_df.loc[sub_index, species_cols] = ll\n",
    "                    sub_index += 1\n",
    "    return cv_preds, labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-person",
   "metadata": {},
   "source": [
    "## Inference loop\n",
    "This is similar to the above loop, the only difference is that it only passes a predictions csv file back.  \n",
    "This is the loop you would use to predict on data, you don't know what is within the audio files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surprising-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_loop(paths,species_cols, df,config, cv_preds,  model, device):\n",
    "\n",
    "    for path in paths:\n",
    "        print(f'loading model {path}')\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        model.eval()\n",
    "        #load the data into dataloaders\n",
    "        dataloader = get_dataloader(df, config=config, mode='test')\n",
    "\n",
    "        tk = tqdm(dataloader, total=len(dataloader))\n",
    "        sub_index = 0\n",
    "        with torch.no_grad():\n",
    "            #we go through all of the data\n",
    "            for i, im in enumerate(tk):\n",
    "                #pass it to the cpu or gpu\n",
    "                im = im.to(device)\n",
    "                #predict on the data\n",
    "                for i, x_partial in enumerate(torch.split(im, 1, dim=1)):\n",
    "                    x_partial = x_partial.squeeze(1)\n",
    "                    if i == 0:\n",
    "                        preds = model(x_partial)\n",
    "                    else:\n",
    "                        # take max over predictions\n",
    "                        preds = torch.max(preds, model(x_partial))\n",
    "                    #get the confidence score of each species and add it to the csv file\n",
    "                o = preds.sigmoid().cpu().numpy()\n",
    "                for val in o:\n",
    "                    cv_preds.loc[sub_index, species_cols] += val\n",
    "                    sub_index += 1\n",
    "    return cv_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-given",
   "metadata": {},
   "source": [
    "## Config\n",
    "The config controls, the batch size( number of images on the GPU), num_works, the sliding window length, duration and other  parameters that may be changed. It also contains the path to where the models weights reside and the folder that contains the audio files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "falling-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    batch_size = 8 #number of images on the GPU. if you have out of memory issues, reducing  this number may help. \n",
    "    num_workers = 0 #number of threads to use when processing, more means faster but can be unstable on windows. \n",
    "    sliding_window = 2.98 #sliding window length\n",
    "    num_classes = len(classes) #number of classes\n",
    "    sr = 32_000 #the samplerate to resample the audio file too\n",
    "    duration = 2.98 # duration of the frame to look at \n",
    "    total_duration = 14.9 # duration of the audio files\n",
    "    nmels = 128 # number of nmel buckets to use when creating a melspectrogram\n",
    "    data_root = '../Test_data_CD' #change this if you wish for it to point to another audio root\n",
    "    model_path = 'models_51' #change this to use other models\n",
    "    mode = 'val'\n",
    "    output_csv = 'output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "invalid-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df,classes=[], drop_classes=False, config=Config()):\n",
    "    #we preprocess the data\n",
    "    proccessed = preprocess(df, classes=classes, drop_classes=drop_classes, mode = config.mode)\n",
    "    if config.mode =='test':\n",
    "        df, cv_preds, species_cols = proccessed\n",
    "    else:\n",
    "        df, cv_preds, species_cols, labels_df = proccessed\n",
    "    # if there is a GPU we load the audio onto the GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #we load a model from the models class\n",
    "    #and get the paths of models from the models path\n",
    "    paths = glob(f'{config.model_path}/*.pth')\n",
    "    model = create_model(len(classes))\n",
    "    model.to(device)\n",
    "    if config.mode !='test':\n",
    "        cv_preds, labels_df = evaluation_loop(paths,species_cols, df,config,  cv_preds, labels_df, model, device)\n",
    "    else:\n",
    "        cv_preds = inference_loop(paths,species_cols, df,config,  cv_preds,  model, device)\n",
    "    #divide by length of folds\n",
    "    cv_preds.loc[:, species_cols] /=len(paths)\n",
    "\n",
    "    print(f'Saving predictions to {config.output_csv}')\n",
    "    cv_preds.to_csv(config.output_csv, index=False)\n",
    "    if config.mode=='test':\n",
    "        return cv_preds\n",
    "    #we evaluate the model using LWlRAP and LRAP\n",
    "    preds = cv_preds.loc[:,species_cols].values.astype(np.float32)\n",
    "    preds = torch.from_numpy(preds)\n",
    "\n",
    "    labels = labels_df.loc[:,species_cols].values.astype(np.float32)\n",
    "    labels = torch.from_numpy(labels)\n",
    "\n",
    "    print(f\"Label weighted label ranking average precision: {LWLRAP(preds, labels):.6}\")\n",
    "    preds = preds.numpy()\n",
    "    labels = labels.numpy()\n",
    "    print(f'Label ranking average precision:{label_ranking_average_precision_score(labels, preds):.6}')\n",
    "    return cv_preds, labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-blowing",
   "metadata": {},
   "source": [
    "This will evaluate on all of the data within the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "generic-thomson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model models_51\\model_0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782157e6556e4aa6a5cd11551e30076c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model models_51\\model_1.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f546cb400a2b4405840f82d2b70ebe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model models_51\\model_2.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b1f263acf74b4c873b85b71c35d4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model models_51\\model_3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844e17f6de704738bb41ab8d718ab749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model models_51\\model_4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde3ef11192e4113ada81fd53791f00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions to output.csv\n",
      "Label weighted label ranking average precision: 0.820846\n",
      "Label ranking average precision:0.850382\n"
     ]
    }
   ],
   "source": [
    "p,l = main(df, classes, drop_classes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-grass",
   "metadata": {},
   "source": [
    "This will evaluate on only classes the model has been trained with, and that are within the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "p,l = main(df, classes, drop_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the mode of the config file from eval to test\n",
    "config = Config()\n",
    "config.mode='test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-gasoline",
   "metadata": {},
   "source": [
    "This will predict on the audio files that are within the CSV file, it will not evaluate on the CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = main(df, classes, drop_classes=False, config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
